# USElections_2024

Four questions, six LLMs, seven swing states, and over 300 data entries. How well can AI support one of the most critical democratic decisions? The short answer is: not very well. Our audit revealed that misinformation knows no political boundaries. Whether it’s small inaccuracies or blatant falsehoods, LLMs have a way of spreading misinformation across state lines, with no regard for party affiliation and little hesitation in delivering their own version of the facts. Even when unintentional, mistakes are never 'minor' when democratic integrity is on the line.

We also noticed that there isn’t a single infallible LLM that consistently avoids errors. On top of that, even with efforts by Big Tech to decrease misinformation, LLMs still act unpredictably, sometimes providing answers even when they were instructed not to. Hallucinations, falsehoods, and echo chambers of misinformation are deeply embedded in these systems, which is why we urgently need better accountability mechanisms.

The present repository contains the LLMs answers, the statistical tests and the main outputs of the report. Additionally, the complete version of the report is included in the repository. 
